{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Survival Classifier\n",
    "\n",
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load up the provided training dataset and index by the provided passenger ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_set = pd.read_csv('./data/train.csv').set_index('PassengerId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a quick peek and make sure everything is as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4                1      0            113803  53.1000  C123        S  \n",
       "5                0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Survived      Pclass         Age       SibSp       Parch        Fare\n",
       "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
       "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proceed as before and further split the tagged training dataset into training and testing subsets. Unlike Orange, `scikit-learn` requires some manual data preprocessing. First, in order to deal with categorical data like `Sex`, dummy variables are introduced. Additionally, `np.ravel` is invoked to transform `y` into the one dimensional array expected by the model's `score` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = pd.get_dummies(training_set[['Pclass', 'Sex', 'Age', 'Fare']])\n",
    "y = training_set[['Survived']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "\n",
    "y_train = np.ravel(y_train)\n",
    "y_test = np.ravel(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier Revisited\n",
    "\n",
    "Now, load up the random forest classifier that was created and pickled in the Orange visual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('titanic-randomforest.pkcls', 'rb') as f:\n",
    "    trained_random_forest = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the domain to ensure alignment in the ordering of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Pclass, Sex=female, Sex=male, Age, Fare | Survived] {PassengerId, Name}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_random_forest.domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " As scikit-learn is [more flexible and less lenient](https://scikit-learn.org/stable/modules/impute.html), there is a need to handle imputing any missing values before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "X_test_imputed = imputer.fit_transform(X_test[['Pclass', 'Sex_female', 'Sex_male', 'Age', 'Fare']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy: 90.582960%'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Accuracy: {:f}%'.format(trained_random_forest.skl_model.score(X_test_imputed, y_test) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated Tuning\n",
    "\n",
    "This initial model was hand-tuned with a guess-and-check approach. Can it be between with fancier tuning? [TPOT](https://epistasislab.github.io/tpot/) optimizes learning pipelines using genetic programming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing missing values in feature set\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=5100, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.8322352143028174\n",
      "Generation 2 - Current best internal CV score: 0.8324573655785246\n",
      "Generation 3 - Current best internal CV score: 0.8337723148961077\n",
      "Generation 4 - Current best internal CV score: 0.8338614414558224\n",
      "Generation 5 - Current best internal CV score: 0.8412562854178306\n",
      "Generation 6 - Current best internal CV score: 0.841504376513156\n",
      "Generation 7 - Current best internal CV score: 0.841504376513156\n",
      "Generation 8 - Current best internal CV score: 0.8443783755021682\n",
      "Generation 9 - Current best internal CV score: 0.8443783755021682\n",
      "Generation 10 - Current best internal CV score: 0.8443783755021682\n",
      "Generation 11 - Current best internal CV score: 0.8443783755021682\n",
      "Generation 12 - Current best internal CV score: 0.8458037353340251\n",
      "Generation 13 - Current best internal CV score: 0.8458037353340251\n",
      "Generation 14 - Current best internal CV score: 0.8458037353340251\n",
      "Generation 15 - Current best internal CV score: 0.8458263495357438\n",
      "Generation 16 - Current best internal CV score: 0.8473847340835927\n",
      "Generation 17 - Current best internal CV score: 0.8473847340835927\n",
      "Generation 18 - Current best internal CV score: 0.8473847340835927\n",
      "Generation 19 - Current best internal CV score: 0.8473847340835927\n",
      "Generation 20 - Current best internal CV score: 0.8473847340835927\n",
      "Generation 21 - Current best internal CV score: 0.8474519115651689\n",
      "Generation 22 - Current best internal CV score: 0.8474519115651689\n",
      "Generation 23 - Current best internal CV score: 0.8488786016441855\n",
      "Generation 24 - Current best internal CV score: 0.8503711389576184\n",
      "Generation 25 - Current best internal CV score: 0.8503711389576184\n",
      "Generation 26 - Current best internal CV score: 0.8503711389576184\n",
      "Generation 27 - Current best internal CV score: 0.8503711389576184\n",
      "Generation 28 - Current best internal CV score: 0.8578571048500813\n",
      "Generation 29 - Current best internal CV score: 0.8578571048500813\n",
      "Generation 30 - Current best internal CV score: 0.8578571048500813\n",
      "Generation 31 - Current best internal CV score: 0.8578571048500813\n",
      "Generation 32 - Current best internal CV score: 0.8578571048500813\n",
      "Generation 33 - Current best internal CV score: 0.8578571048500813\n",
      "Generation 34 - Current best internal CV score: 0.8578571048500813\n",
      "Generation 35 - Current best internal CV score: 0.8578571048500813\n",
      "Generation 36 - Current best internal CV score: 0.8578571048500813\n",
      "Generation 37 - Current best internal CV score: 0.8578571048500813\n",
      "Generation 38 - Current best internal CV score: 0.8578571048500813\n",
      "Generation 39 - Current best internal CV score: 0.8578571048500813\n",
      "Generation 40 - Current best internal CV score: 0.8578571048500813\n",
      "Generation 41 - Current best internal CV score: 0.8578571048500813\n",
      "Generation 42 - Current best internal CV score: 0.8578571048500813\n",
      "Generation 43 - Current best internal CV score: 0.8578571048500813\n",
      "Generation 44 - Current best internal CV score: 0.8578571048500813\n",
      "Generation 45 - Current best internal CV score: 0.8578571048500813\n",
      "Generation 46 - Current best internal CV score: 0.8578571048500813\n",
      "Generation 47 - Current best internal CV score: 0.8578571048500813\n",
      "Generation 48 - Current best internal CV score: 0.8578571048500813\n",
      "Generation 49 - Current best internal CV score: 0.8578571048500813\n",
      "Generation 50 - Current best internal CV score: 0.8578571048500813\n",
      "\n",
      "Best pipeline: ExtraTreesClassifier(SelectFwe(LogisticRegression(OneHotEncoder(PolynomialFeatures(input_matrix, degree=2, include_bias=False, interaction_only=False), minimum_fraction=0.15, sparse=False, threshold=10), C=10.0, dual=False, penalty=l2), alpha=0.038), bootstrap=False, criterion=entropy, max_features=0.3, min_samples_leaf=2, min_samples_split=8, n_estimators=100)\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "\n",
    "tpot = TPOTClassifier(generations=50, population_size=100, cv=10, n_jobs=-1, memory='auto', verbosity=2)\n",
    "tpot.fit(X_train, y_train)\n",
    "tpot.export('tpot_titanic_pipeline.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing missing values in feature set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bishop/miniconda3/envs/titanic/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.pvalues_ < self.alpha / len(self.pvalues_))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Accuracy: 81.165919%'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Accuracy: {:f}%'.format(tpot.score(X_test, y_test) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "With trained models in hand, load up the test dataset, massage the data as needed, add predictions, and export to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing missing values in feature set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bishop/miniconda3/envs/titanic/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.pvalues_ < self.alpha / len(self.pvalues_))\n"
     ]
    }
   ],
   "source": [
    "test_set = pd.read_csv('./data/test.csv').set_index('PassengerId')\n",
    "test_set_dummies = pd.get_dummies(test_set[['Pclass', 'Sex', 'Age', 'Fare']])\n",
    "\n",
    "# Hand-tuned\n",
    "test_set_imputed = imputer.fit_transform(test_set_dummies[['Pclass', 'Sex_female', 'Sex_male', 'Age', 'Fare']])\n",
    "test_set['Survived'] = trained_random_forest.skl_model.predict(test_set_imputed)\n",
    "test_set['Survived'] = test_set['Survived'].astype(int)\n",
    "test_set[['Survived']].to_csv('final-random-forest.csv')\n",
    "\n",
    "# TPOT optimized\n",
    "test_set['Survived'] = tpot.predict(test_set_dummies)\n",
    "test_set['Survived'] = test_set['Survived'].astype(int)\n",
    "test_set[['Survived']].to_csv('final-tpot.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
